{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc869ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T10:06:37.853103Z",
     "start_time": "2024-02-14T10:06:28.303591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: sniffio in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: certifi in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.24)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/leonarddavid/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb91447",
   "metadata": {},
   "source": [
    "# Getting data from Mergeflow's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31aea093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T10:08:32.670923Z",
     "start_time": "2024-02-15T10:08:29.869883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 documents.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load variables from .env file\n",
    "mergeflow_api_key = os.getenv('MERGEFLOW_API_KEY')\n",
    "\n",
    "# the API call\n",
    "query = 'factory automation' # topic is \"factory automation\"\n",
    "dataset = '&sp=3814' # dataset: industry news\n",
    "rows = str(3) # first 3 docs only\n",
    "\n",
    "# in the url below, replace \"fw\" by your user name. You can see your user name at mergeflow.net\n",
    "# -> Account -> the string in angle brackets\n",
    "url = 'https://mergeflow.net/api/v1/leonard/search/getContent?q=' + query + dataset + '&rows=' + rows\n",
    "\n",
    "# Define the headers to be sent with the request\n",
    "headers = {\n",
    "    'MergeflowNet-Api-Auth-Key': mergeflow_api_key\n",
    "}\n",
    "\n",
    "# Get and print the response\n",
    "response = requests.post(url, headers=headers)\n",
    "\n",
    "mergeflow_docs = []\n",
    "\n",
    "# Check the response status code and content\n",
    "if response.status_code == 200:\n",
    "    mergeflow_response_json = response.json()\n",
    "    \n",
    "    #pretty-print the JSON response -- useful to understand what the JSON looks like\n",
    "    #pretty_json = json.dumps(mergeflow_response_json, indent=4)\n",
    "    #print(pretty_json)\n",
    "    \n",
    "    # get title, URL, date, and content\n",
    "    for document in mergeflow_response_json['Documents']:\n",
    "        current_doc = {\n",
    "            'title': document['Title'],\n",
    "            'date': document['Date'],\n",
    "            'url': document['Url'],\n",
    "            'content': document['Content'][:5000]\n",
    "        }\n",
    "        \n",
    "        mergeflow_docs.append(current_doc)\n",
    "        #print(content)        \n",
    "\n",
    "    print('Found ' + str(len(mergeflow_docs)) + ' documents.')\n",
    "\n",
    "else:\n",
    "    print('Request failed with status code:', response.status_code)\n",
    "    print(response.text)  # Print the response text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be09112",
   "metadata": {},
   "source": [
    "# Answering questions on the results with OpenAI GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e00c882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T11:21:02.733402Z",
     "start_time": "2024-02-15T11:20:41.366886Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Problem:** Lack of personalized and adaptive automation systems in factory automation, limiting efficiency and flexibility in production processes.\n",
      "  \n",
      "- **User Group:** Manufacturing workers and supervisors in factories.\n",
      "\n",
      "- **Pain Point:** Workers and supervisors face challenges in optimizing workflows and adapting to changing production needs due to rigid and non-adaptive automation systems, leading to inefficiencies, downtime, and potential errors in operations.\n",
      "\n",
      "---\n",
      "\n",
      "- **Problem:** Integrating private 5G networks and AI technology into factory automation systems to enhance connectivity, data processing, and operational efficiency.\n",
      "\n",
      "- **User Group:** Factory managers and engineers in charge of optimizing production processes and equipment performance.\n",
      "\n",
      "- **Pain Point:** Difficulty in seamlessly incorporating complex private 5G and AI solutions into existing automation systems, leading to integration challenges, potential downtime, and the need for specialized training to maximize benefits.\n",
      "\n",
      "---\n",
      "\n",
      "- **Problem:** Lack of standardized communication protocols for M5 circular connectors in factory automation leads to compatibility issues and integration challenges.\n",
      "- **User Group:** Automation engineers and maintenance technicians.\n",
      "- **Pain Point:** Incompatibility between different devices using M5 connectors results in downtime, inefficiencies, and increased maintenance costs due to manual workarounds and troubleshooting efforts.\n",
      "\n",
      "---\n",
      "\n",
      "**Problem:** Lack of personalized and adaptive automation systems in factory automation, limiting efficiency and flexibility in production processes.\n",
      "\n",
      "- Size of user group: 3 (large target group)\n",
      "- Relevancy of pain point to factory automation industry: 3 (very relevant to users)\n",
      "- Specificity of the problem: 3 (specific and not generic problem)\n",
      "\n",
      "Justification: The problem affects a large number of manufacturing workers and supervisors in factories, is highly relevant to the industry, and addresses a specific pain point. \n",
      "\n",
      "Overall score: 9 out of 9.\n",
      "\n",
      "---\n",
      "\n",
      "**Problem:** Integrating private 5G networks and AI technology into factory automation systems.\n",
      "\n",
      "- Size of user group: 2 (medium target group)\n",
      "- Relevancy of pain point: 3 (very relevant to users)\n",
      "- Specificity of the problem: 3 (specific and not generic problem)\n",
      "\n",
      "Overall score: 8/9. This problem is highly relevant to factory automation users, specific, and has a medium-sized target group.\n",
      "\n",
      "---\n",
      "\n",
      "**Problem:** Lack of standardized communication protocols for M5 circular connectors in factory automation.\n",
      "\n",
      "- Size of user group: 2 (medium target group) - There is a moderate number of automation engineers and maintenance technicians in the industry.\n",
      "- Relevancy of pain point: 3 (very relevant to users) - Compatibility issues and integration challenges directly impact the efficiency and costs of factory automation operations.\n",
      "- Specificity of the problem: 3 (specific and not generic problem) - The lack of standardized communication protocols for M5 circular connectors is a very industry-specific issue.\n",
      "\n",
      "Overall score: 8 out of 9.\n",
      "\n",
      "Justification: The problem is highly relevant to a significant user group within factory automation, addressing a specific pain point in the industry.\n",
      "\n",
      "---\n",
      "\n",
      "The problem with the highest overall rating is the lack of personalized and adaptive automation systems in factory automation, impacting a large user group of manufacturing workers and supervisors. The specific pain point is the challenge in optimizing workflows and adapting to changing production needs, leading to inefficiencies and potential errors. This problem scores 9/9 due to its large target group, high relevancy to the factory automation industry, and specificity in addressing a critical pain point.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "\n",
    "You are Senior Vice President Technology and Innovation & CTO of Factory Automation. When you evaluate a new business idea, you strictly adhere to the following guiding principles:\n",
    "        - Focus on Sense&Act.\n",
    "        - Prioritize quick, low-investment idea testing.\n",
    "        - Aim for large profits with smaller budgets, avoiding investments over 10-15 million per portfolio element.\n",
    "        - Target a minimum 10 million EUR annual revenue.\n",
    "        - Specialize in LLMs in Engineering and Operations.\n",
    "        - Avoid new ecosystem creation.\n",
    "        - Core business: Sense&Act, PMA, Scada, PLCs.\n",
    "        - Prioritize product over solution business for scalability.\n",
    "        - Consider AI as a potential product.\n",
    "        - Ensure all initiatives align with business profitability.\n",
    "        - Make investment decisions as if using personal funds.\n",
    "        - Aim for non-cannibalizing, fringe markets.\n",
    "        - PLCs are scalable; seek similar scalability in AI applications.\n",
    "        - Validate ideas with business units and customer feedback.\n",
    "        - Avoid focusing solely on infrastructure to ensure profitable outcomes.\n",
    "        \n",
    "        \"\"\"\n",
    "# Initialize an empty list to store problem messages\n",
    "problems_list = []\n",
    "\n",
    "for doc in mergeflow_docs:\n",
    "\n",
    "    user_prompt1 = f\"\"\"\n",
    "    Consider the text below, delimited by ```, in the area of {query}:\n",
    "    ```\n",
    "    {doc['content']}\n",
    "    ```\n",
    "        I'm interested in exploring problems that will occur in the area of {query} using the concept of the adjacent possible, as outlined by Stuart Kauffman and popularized by Steven Johnson. This approach emphasizes incremental innovation by considering what's just beyond the current technological, cultural, or conceptual boundaries, yet still achievable with existing resources or slight advancements. \n",
    "        \n",
    "        I'm looking for ideas that are not far-fetched but are innovative problems that could occur as a result of what currently exists, tapping into the untapped potential lying just outside the present scope of {query}.\n",
    "\n",
    "        Given this framework, please analyze the current trends, technologies, consumer behaviors, and market needs in {query}. Identify where there might be gaps or unmet needs that align with the concept of the adjacent possible. Consider the following:\n",
    "\n",
    "        Technological Advancements: What recent technological developments have occurred, and how might they open new opportunities for innovation or improvement in factory automation?\n",
    "        Consumer Behavior Shifts: How have consumer preferences and behaviors evolved recently, and what does this imply about potential future needs or desires?\n",
    "        Regulatory Changes: Are there any recent or upcoming changes in regulations that might create new opportunities or necessitate innovations in factory automation?\n",
    "        Cross-industry Inspiration: Look at how other industries are innovating. Are there any ideas or technologies that could be adapted or extended to fit the context of factory automation?\n",
    "\n",
    "        For the problem, please output: \n",
    "        - The problem (max 50 words)\n",
    "        - Which user group is impacted by this problem the most (max 25 words)\n",
    "        - What is the specific pain point for this user group resulting from the problem (max 50 words)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt1}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    \n",
    "    # Append the completion message content to the problems_list\n",
    "    problems_list.append(completion.choices[0].message.content)\n",
    "    \n",
    "    # This prints the content of the output in a more readable way\n",
    "    print(completion.choices[0].message.content)\n",
    "    print(\"\\n---\\n\")  # This adds a separator between the content blocks for readability\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# second agent:\n",
    "\n",
    "# Now, iterate over problems_list to rate each problem\n",
    "rated_problems_list = []\n",
    "for problem in problems_list:\n",
    "    user_prompt2 = f\"\"\"\n",
    "    Before you give me any output, please rate the problems according to the following criteria. Please be very critical in your ratings and only give limited number of 3:\n",
    "        - Size of user group (how many of the mentioned customers exist) (1 = small target group, 2 = medium target group, 3 = large target group)\n",
    "        - Relevancy of pain point to the specific industry of {query} and the respective user group (e.g., patty not relevant for factory automation) (1 = not relevant to users, 2 = medium relevant to users, 3 = very relevant to users)\n",
    "        - How specific is the problem? (1 = very generic problem, 2 = medium generic, 3 = specific and not generic problem)\n",
    "\n",
    "    Given the problem:\n",
    "    {problem}\n",
    "\n",
    "    Please repeat the name of the problem and then output the ratings and a one-sentence justification (max 20 words).\n",
    "    Add up the three ratings you gave to an overall score out of 9.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt2}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Assume we store the rated problem details for later use\n",
    "    rated_problems_list.append(completion.choices[0].message.content)\n",
    "\n",
    "    # Print the rated problem for immediate feedback\n",
    "    print(completion.choices[0].message.content)\n",
    "    print(\"\\n---\\n\")\n",
    "    \n",
    "\n",
    "# third agent \n",
    "\n",
    "user_prompt3 = f\"\"\"\n",
    "\n",
    "    Consider the following problems: {problems_list}\n",
    "    Consider the corresponding ratings: {rated_problems_list}\n",
    "    \n",
    "    Please output the problem with the highest overall rating in the {rated_problems_list}, including: \n",
    "        - The problem (max 50 words)\n",
    "        - Which user group is impacted by this problem the most (max 25 words)\n",
    "        - What is the specific pain point for this user group resulting from the problem (max 50 words)\n",
    "        - One sentence that summarises the three selection criteria (Size of user group / Relevancy of pain point to the specific industry of {query} and the respective user group / How specific is the problem)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "completion = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt3}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "\n",
    "# Print the rated problem for immediate feedback\n",
    "print(completion.choices[0].message.content)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe0a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T10:25:20.446624Z",
     "start_time": "2024-02-15T10:25:20.279772Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19516ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T11:07:39.614919Z",
     "start_time": "2024-02-15T11:07:18.884085Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
