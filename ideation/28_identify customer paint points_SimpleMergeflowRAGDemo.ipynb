{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc869ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: openai in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ferdi\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb91447",
   "metadata": {},
   "source": [
    "# Getting data from Mergeflow's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31aea093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 documents.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv # stores API keys for OpenAI and Mergeflow \n",
    "\n",
    "load_dotenv()  # Load variables from .env file\n",
    "mergeflow_api_key = os.getenv('MERGEFLOW_API_KEY') # Assign Mergeflow API\n",
    "\n",
    "# the API call\n",
    "query = 'factory+automation' # topic is \"large language model\"factory automation\n",
    "dataset = '&q=*%5bfundingcompany%7cfundingproject%7cfundingorganization%5d&sp=2572' # access dataset from mergeflow - in this case venture capital investments\n",
    "rows = str(10) # first 10 docs only\n",
    "\n",
    "# in the url below, replace \"fw\" by your user name. You can see your user name at mergeflow.net\n",
    "# -> Account -> the string in angle brackets\n",
    "url = 'https://mergeflow.net/api/v1/ferdinandk/search/getContent?q=' + query + dataset + '&rows=' + rows\n",
    "\n",
    "# Define the headers to be sent with the request\n",
    "headers = {\n",
    "    'MergeflowNet-Api-Auth-Key': mergeflow_api_key\n",
    "}\n",
    "\n",
    "# Get and print the response\n",
    "response = requests.post(url, headers=headers)\n",
    "\n",
    "mergeflow_docs = []\n",
    "\n",
    "# Check the response status code and content\n",
    "if response.status_code == 200:\n",
    "    mergeflow_response_json = response.json()\n",
    "    \n",
    "    # Pretty-print the JSON response -- useful to understand what the JSON looks like\n",
    "    #pretty_json = json.dumps(mergeflow_response_json, indent=4)\n",
    "    #print(pretty_json)\n",
    "    \n",
    "    # get title, URL, date, and content\n",
    "    for document in mergeflow_response_json['Documents']:\n",
    "        current_doc = {\n",
    "            'title': document['Title'],\n",
    "            'date': document['Date'],\n",
    "            'url': document['Url'],\n",
    "            'content': document['Content']\n",
    "        }\n",
    "        \n",
    "        mergeflow_docs.append(current_doc)\n",
    "        #print(content)        \n",
    "\n",
    "    print('Found ' + str(len(mergeflow_docs)) + ' documents.')\n",
    "\n",
    "else:\n",
    "    print('Request failed with status code:', response.status_code)\n",
    "    print(response.text)  # Print the response text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be09112",
   "metadata": {},
   "source": [
    "# Answering questions on the results with OpenAI GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e00c882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the criteria provided, I have ranked the different problems as follows:\n",
      "\n",
      "1. Problem with Rank 1 out of 10:\n",
      "   - Problem: Inefficient production line changeovers leading to downtime.\n",
      "   - Resulting Pain Point: Decreased productivity and increased costs due to extended periods of inactivity during changeovers.\n",
      "   - Most Affected Customers: Manufacturing companies with high product variety and frequent changeovers.\n",
      "   - Priority Reasoning: This problem affects a wide range of manufacturing sectors and has a significant impact on productivity and costs, making it a top priority for many customers.\n",
      "\n",
      "2. Problem with Rank 4 out of 10:\n",
      "   - Problem: Inefficient utilization of production line assets leading to downtime and decreased productivity.\n",
      "   - Resulting Pain Point: Significant financial losses due to unplanned downtime and delays in production schedules.\n",
      "   - Most Affected Customers: Manufacturing companies in sectors with high-volume production such as automotive and electronics.\n",
      "   - Priority Reasoning: The financial impact of inefficient asset utilization on high-volume production sectors like automotive and electronics highlights the critical need for a solution.\n",
      "\n",
      "3. Problem with Rank 9 out of 10:\n",
      "   - Problem: Lack of interoperability and integration between different factory automation systems and equipment.\n",
      "   - Resulting Pain Point: Inefficiency and increased downtime due to manual intervention required for data exchange.\n",
      "   - Most Affected Customers: Manufacturing companies in the automotive sector due to the complex nature of their production lines involving machinery from multiple suppliers.\n",
      "   - Priority Reasoning: Addressing interoperability challenges is crucial for streamlining operations and optimizing production efficiency, especially in complex sectors like automotive manufacturing.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY') # Assign OpenAI API\n",
    "\n",
    "system_prompt = f\"\"\"You are Senior Vice President Technology and Innovation & CTO of Factory Automation. Your work is highly cruical and you are responsible of coming up with the next best innovation.\n",
    "        \"\"\"\n",
    "problem = {}\n",
    "i = 0\n",
    "\n",
    "for doc in mergeflow_docs: #stores all the problems in 1 string \n",
    "    user_prompt = f\"\"\"\n",
    "    Consider the text below, delimited by ```, in the area of {query}:\n",
    "    ```\n",
    "    {doc['content']}\n",
    "    ```    \n",
    "    You want to find pressing problems of your customers which would be worth solving.\n",
    "    - Your customers are manufacturing companies across various sectors such as automotive, electronics, consumer goods, pharmaceuticals, food and beverage, and aerospace. \n",
    "    - Take a deep breath and work on this problem step by step. \n",
    "    - Step 1: Please find 1 specific problem which seems highly problematic for your clients.\n",
    "    - Step 2: For this problem, please name the specific resulting pain point of the customer and the customer journey.\n",
    "    - Step 3: For this problem, please specify which type of customer has the identified problem most often.\n",
    "    - Step 4: For this problem, please write only 75 words. \n",
    "    \"\"\"\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    problem[i] = completion.choices[0].message\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "#Rate the problems from the 1 string and give out top 3     \n",
    "user_prompt1 = f\"\"\"\n",
    "    Consider the following problems {problem}:\n",
    "    ```    \n",
    "    Take a deep breath and work on this problem step by step. \n",
    "    \n",
    "    Please rank the different problems according to the following criteria:\n",
    "    - Amount of customers who have this problem (the more customers, the better)\n",
    "    - Need to be fixed and hence the willingness to pay of these customers (the higher the willingness to pay, the better)\n",
    "    - Amount of existent solutions on the market (the fewer effective existing solutions to the problem, the better)\n",
    "    \n",
    "    Please make sure that the ideas ranked in the first three places are not very similar to each other.\n",
    "    \n",
    "    Please give me more details about the 3 problems ranked highest:\n",
    "    For each problem write a 50 word paragraph containing the following clearly separated 5 contents: \n",
    "    1) Start with the problems ranking in the format \"Problem with rank X out of 10\". For example, if you have 10 problems your second highest rated problem should start with \"Problem with Rank 2 out of 10\"\n",
    "    2) State the problem\n",
    "    3) Name the specific resulting pain point of the customer\n",
    "    4) Specify which type of customers has the identified problem most often\n",
    "    5) Short reasoning for priority (1 sentence)\n",
    "    \"\"\"\n",
    "    \n",
    "completion = openai.chat.completions.create(\n",
    "model=\"gpt-3.5-turbo-0125\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": system_prompt},\n",
    "{\"role\": \"user\", \"content\": user_prompt1}\n",
    "],\n",
    "temperature=0.7,\n",
    "max_tokens=2000,\n",
    "top_p=0.95,\n",
    "frequency_penalty=0,\n",
    "presence_penalty=0,\n",
    "stop=None\n",
    ")\n",
    "\n",
    "    \n",
    "print(completion.choices[0].message.content) # This prints the content of the output in a more readable way\n",
    "print(\"\\n---\\n\")  # This adds a separator between the messages for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a124fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e8e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
